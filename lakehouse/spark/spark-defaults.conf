# Required packages (including spark-connect for remote PySpark)
spark.jars.packages org.apache.spark:spark-connect_2.12:3.5.5,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262,org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.3,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.77.1

# S3 defaults for MinIO (warehouse bucket)
spark.hadoop.fs.s3a.impl org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.path.style.access true
spark.hadoop.fs.s3a.aws.credentials.provider org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider

# MinIO endpoint (all S3 access goes through MinIO)
spark.hadoop.fs.s3a.endpoint http://minio:9000

# Iceberg catalog configuration with Nessie
spark.sql.catalog.iceberg org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.iceberg.catalog-impl org.apache.iceberg.nessie.NessieCatalog
spark.sql.catalog.iceberg.uri http://nessie:19120/api/v1
spark.sql.catalog.iceberg.ref main
spark.sql.catalog.iceberg.io-impl org.apache.iceberg.aws.s3.S3FileIO
spark.sql.catalog.iceberg.s3.endpoint http://minio:9000
spark.sql.catalog.iceberg.warehouse s3://warehouse/

# Nessie Spark extensions
spark.sql.extensions org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions

# Default catalog
spark.sql.defaultCatalog iceberg

# Thrift server binding (for remote connections)
spark.sql.hive.thriftServer.singleSession false

# Spark Connect (for remote PySpark)
spark.connect.grpc.binding.address 0.0.0.0
spark.connect.grpc.binding.port 15002
